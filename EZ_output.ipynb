{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EZ.word import word_DVs, word_means\n",
    "from EZ.sentence import Sentence\n",
    "from EZ.fixation import Fixation\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_on_zero(df, column_name='fix_id'):\n",
    "    # Find indices where the column equals 0\n",
    "    df = df.reset_index()\n",
    "    split_indices = df.index[df[column_name] == 0].tolist()\n",
    "    # Add end index\n",
    "    split_indices.append(len(df))\n",
    "    # Create a list of DataFrames\n",
    "    dfs = [df.iloc[split_indices[i]:split_indices[i+1]].reset_index(drop=True) for i in range(len(split_indices)-1)]\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_info_df = pd.read_csv('/data/home/shared/onestop/OneStop_v1_20250126/lacclab_processed/ia_Paragraph.csv', engine=\"pyarrow\")\n",
    "word_info_df = word_info_df[word_info_df[\"article_id\"] != 0] # filter out practice article\n",
    "word_info_df = word_info_df[word_info_df[\"repeated_reading_trial\"] == 0] # use only non repeated reading\n",
    "word_info_df = word_info_df[word_info_df[\"question_preview\"] == 0] # use only non question preview cases\n",
    "word_info_df['IA_LABEL'] = word_info_df.IA_LABEL.replace('\\t(.*)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:16<00:00, 20.80it/s]\n"
     ]
    }
   ],
   "source": [
    "paragraphs = []\n",
    "for unique_paragraph_id, text_spacing_version in tqdm(word_info_df[['unique_paragraph_id', 'text_spacing_version']].drop_duplicates().values.tolist()):\n",
    "\t\t\tfull_sn_df = word_info_df[(word_info_df.unique_paragraph_id==unique_paragraph_id) & (word_info_df.text_spacing_version == text_spacing_version)]\n",
    "\t\t\tfirst_sub = full_sn_df.drop_duplicates([\"unique_paragraph_id\", \"text_spacing_version\"]).participant_id.values[0]\n",
    "\t\t\tsn_sub = full_sn_df[full_sn_df.participant_id == first_sub]\n",
    "\t\t\tparagraphs.append(sn_sub.groupby(['unique_paragraph_id', 'text_spacing_version'])['word_length'].apply(list).reset_index())\n",
    "\t\t\t\n",
    "paragraphs = pd.concat(paragraphs, axis=0)\n",
    "\n",
    "paragraphs_dict = {}\n",
    "for i, row in paragraphs.iterrows():\n",
    "    paragraphs_dict[(row[\"unique_paragraph_id\"], row[\"text_spacing_version\"])] = Sentence(i, row[\"word_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "folder_path = \"results/Eyettention\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "eyettention_outputs = {}\n",
    "\n",
    "# Loop through each CSV file and load it into a DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    eyettention_outputs[file] = df  # Store DataFrame in dictionary with filename as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started full_eyettention_output_fold_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Combos: 100%|██████████| 339/339 [01:57<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started full_eyettention_output_fold_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Combos: 100%|██████████| 339/339 [01:34<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_combo(combo_df):\n",
    "        \"\"\"Processes a single combo in parallel.\"\"\"\n",
    "        combo, df_list = combo_df\n",
    "        processed_fix_lists = []\n",
    "\n",
    "        for df in df_list:\n",
    "            df_to_fix_list = [Fixation(row[\"sp_fix_dur\"], row[\"fix_id\"], row[\"sp_fix_pos\"]) for _, row in df.iterrows()]\n",
    "            processed_fix_lists.append(df_to_fix_list)\n",
    "\n",
    "        # Deep copy paragraph to prevent race conditions\n",
    "        adjusted_paragraph = copy.deepcopy(paragraphs_dict[combo])\n",
    "\n",
    "        for fix_list in processed_fix_lists:\n",
    "            adjusted_paragraph.subj_number += 1\n",
    "            adjusted_paragraph = word_DVs(adjusted_paragraph, fix_list)\n",
    "\n",
    "        word_means(adjusted_paragraph)\n",
    "\n",
    "        return combo, adjusted_paragraph\n",
    "\n",
    "fold_dict = {}\n",
    "\n",
    "for fold_file in sorted(eyettention_outputs.keys()):\n",
    "    print(f\"Started {fold_file}\")\n",
    "    processed_fold = {}\n",
    "    output_df = eyettention_outputs[fold_file]\n",
    "    \n",
    "    # Group and split data\n",
    "    grouped_dfs = {key: group for key, group in output_df.groupby(['unique_paragraph_id', 'text_spacing_version'])}\n",
    "    grouped_dfs = {key: split_df_on_zero(group) for key, group in grouped_dfs.items()}\n",
    "\n",
    "    # Parallelize at the combo level with progress tracking\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(process_combo, combo_df): combo_df[0] for combo_df in grouped_dfs.items()}\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing Combos\"):\n",
    "            combo, adjusted_paragraph = future.result()\n",
    "            processed_fold[combo] = adjusted_paragraph\n",
    "        \n",
    "        executor.shutdown(wait=True)\n",
    "\n",
    "    fold_dict[fold_file] = processed_fold  # Fix: store result under `fold_file`, not string `'fold_file'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_file, combos_dict in fold_dict.items():\n",
    "        cols = [\"unique_paragraph_id\", \"text_spacing_version\", \"IA_ID\", \"SFD\", \"FFD\", \"GD\", \"TT\", \"GP\", \"PrF\", \"Pr1\", \"Pr2\", \"PrS\", \n",
    "\"NRegIn\", \"NRegOut\", \"NRegOutFull\", \"FirstPassGD\", \"FirstPassFFD\", \"FirstFixProg\", \"NFixations\"]\n",
    "        output_dict = {col: [] for col in cols}\n",
    "        for combo, sentence in combos_dict.items():\n",
    "                for i, word in enumerate(sentence.word):\n",
    "                        output_dict[\"SFD\"].append(word.dv.SFD)\n",
    "                        output_dict[\"FFD\"].append(word.dv.FFD)\n",
    "                        output_dict[\"GD\"].append(word.dv.GD)\n",
    "                        output_dict[\"TT\"].append(word.dv.TT)\n",
    "                        output_dict[\"GP\"].append(word.dv.GoPast)\n",
    "                        output_dict[\"PrF\"].append(word.dv.PrF)\n",
    "                        output_dict[\"Pr1\"].append(word.dv.Pr1)\n",
    "                        output_dict[\"Pr2\"].append(word.dv.Pr2)\n",
    "                        output_dict[\"PrS\"].append(word.dv.PrS)\n",
    "                        output_dict[\"NRegIn\"].append(word.dv.NRegIn)\n",
    "                        output_dict[\"NRegOut\"].append(word.dv.NRegOut)\n",
    "                        output_dict[\"NRegOutFull\"].append(word.dv.NRegOutFull)\n",
    "                        output_dict[\"FirstPassGD\"].append(word.dv.FirstPassGD)\n",
    "                        output_dict[\"FirstPassFFD\"].append(word.dv.FirstPassFFD)\n",
    "                        output_dict[\"FirstFixProg\"].append(word.dv.FirstFixProg)\n",
    "                        output_dict[\"NFixations\"].append(word.dv.NFixations)\n",
    "                        output_dict[\"IA_ID\"].append(i)\n",
    "                output_dict[\"unique_paragraph_id\"] += [combo[0]]*len(sentence.word)\n",
    "                output_dict[\"text_spacing_version\"] += [combo[1]]*len(sentence.word)\n",
    "\n",
    "        fold_ia_report = pd.DataFrame(output_dict)\n",
    "        fold_ia_report = fold_ia_report.round({col: 3 for col in fold_ia_report.select_dtypes(include=['float64']).columns})\n",
    "        fold_ia_report = fold_ia_report.sort_values([\"unique_paragraph_id\", \"text_spacing_version\", \"IA_ID\"])\n",
    "        fold_ia_report.to_csv(f\"/data/home/shared/Eyettention/iaReports/{fold_file}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_paragraph_id</th>\n",
       "      <th>text_spacing_version</th>\n",
       "      <th>IA_ID</th>\n",
       "      <th>SFD</th>\n",
       "      <th>FFD</th>\n",
       "      <th>GD</th>\n",
       "      <th>TT</th>\n",
       "      <th>GP</th>\n",
       "      <th>PrF</th>\n",
       "      <th>Pr1</th>\n",
       "      <th>Pr2</th>\n",
       "      <th>PrS</th>\n",
       "      <th>NRegIn</th>\n",
       "      <th>NRegOut</th>\n",
       "      <th>NRegOutFull</th>\n",
       "      <th>FirstPassGD</th>\n",
       "      <th>FirstPassFFD</th>\n",
       "      <th>FirstFixProg</th>\n",
       "      <th>NFixations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>1_10_Adv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>1_10_Adv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>106.866</td>\n",
       "      <td>194.738</td>\n",
       "      <td>253.262</td>\n",
       "      <td>555.295</td>\n",
       "      <td>253.262</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>253.516</td>\n",
       "      <td>194.756</td>\n",
       "      <td>0.998</td>\n",
       "      <td>2.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>1_10_Adv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>109.217</td>\n",
       "      <td>195.523</td>\n",
       "      <td>242.708</td>\n",
       "      <td>446.648</td>\n",
       "      <td>316.558</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.291</td>\n",
       "      <td>257.809</td>\n",
       "      <td>195.781</td>\n",
       "      <td>0.936</td>\n",
       "      <td>2.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>1_10_Adv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>149.992</td>\n",
       "      <td>201.671</td>\n",
       "      <td>147.626</td>\n",
       "      <td>294.631</td>\n",
       "      <td>173.570</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.088</td>\n",
       "      <td>221.237</td>\n",
       "      <td>205.407</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>1_10_Adv_1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>129.831</td>\n",
       "      <td>202.662</td>\n",
       "      <td>170.182</td>\n",
       "      <td>319.071</td>\n",
       "      <td>213.826</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.172</td>\n",
       "      <td>210.294</td>\n",
       "      <td>204.854</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33062</th>\n",
       "      <td>3_9_Ele_4</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>95.682</td>\n",
       "      <td>184.829</td>\n",
       "      <td>124.369</td>\n",
       "      <td>360.035</td>\n",
       "      <td>252.486</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.150</td>\n",
       "      <td>206.195</td>\n",
       "      <td>185.499</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33063</th>\n",
       "      <td>3_9_Ele_4</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>91.689</td>\n",
       "      <td>184.585</td>\n",
       "      <td>121.599</td>\n",
       "      <td>370.364</td>\n",
       "      <td>244.046</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.255</td>\n",
       "      <td>191.488</td>\n",
       "      <td>185.307</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33064</th>\n",
       "      <td>3_9_Ele_4</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>91.171</td>\n",
       "      <td>184.837</td>\n",
       "      <td>131.861</td>\n",
       "      <td>384.148</td>\n",
       "      <td>381.631</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.293</td>\n",
       "      <td>195.961</td>\n",
       "      <td>185.713</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33065</th>\n",
       "      <td>3_9_Ele_4</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>103.562</td>\n",
       "      <td>184.922</td>\n",
       "      <td>146.699</td>\n",
       "      <td>360.558</td>\n",
       "      <td>873.936</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.422</td>\n",
       "      <td>204.108</td>\n",
       "      <td>186.470</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33066</th>\n",
       "      <td>3_9_Ele_4</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>100.431</td>\n",
       "      <td>185.882</td>\n",
       "      <td>190.068</td>\n",
       "      <td>377.318</td>\n",
       "      <td>1337.757</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.670</td>\n",
       "      <td>220.326</td>\n",
       "      <td>186.419</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36983 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_paragraph_id  text_spacing_version  IA_ID      SFD      FFD  \\\n",
       "2073           1_10_Adv_1                     0      0    0.000    0.000   \n",
       "2074           1_10_Adv_1                     0      1  106.866  194.738   \n",
       "2075           1_10_Adv_1                     0      2  109.217  195.523   \n",
       "2076           1_10_Adv_1                     0      3  149.992  201.671   \n",
       "2077           1_10_Adv_1                     0      4  129.831  202.662   \n",
       "...                   ...                   ...    ...      ...      ...   \n",
       "33062           3_9_Ele_4                     0     73   95.682  184.829   \n",
       "33063           3_9_Ele_4                     0     74   91.689  184.585   \n",
       "33064           3_9_Ele_4                     0     75   91.171  184.837   \n",
       "33065           3_9_Ele_4                     0     76  103.562  184.922   \n",
       "33066           3_9_Ele_4                     0     77  100.431  185.882   \n",
       "\n",
       "            GD       TT        GP    PrF    Pr1    Pr2    PrS  NRegIn  \\\n",
       "2073     0.000    0.000     0.000  1.000  0.000  0.000  1.000   0.000   \n",
       "2074   253.262  555.295   253.262  0.999  0.780  0.218  0.002   0.913   \n",
       "2075   242.708  446.648   316.558  0.962  0.737  0.199  0.064   0.149   \n",
       "2076   147.626  294.631   173.570  0.547  0.341  0.024  0.635   0.176   \n",
       "2077   170.182  319.071   213.826  0.713  0.562  0.015  0.423   0.219   \n",
       "...        ...      ...       ...    ...    ...    ...    ...     ...   \n",
       "33062  124.369  360.035   252.486  0.473  0.260  0.028  0.712   0.196   \n",
       "33063  121.599  370.364   244.046  0.474  0.291  0.010  0.699   0.196   \n",
       "33064  131.861  384.148   381.631  0.513  0.331  0.019  0.650   0.210   \n",
       "33065  146.699  360.558   873.936  0.502  0.338  0.031  0.631   0.142   \n",
       "33066  190.068  377.318  1337.757  0.497  0.376  0.078  0.546   0.032   \n",
       "\n",
       "       NRegOut  NRegOutFull  FirstPassGD  FirstPassFFD  FirstFixProg  \\\n",
       "2073     0.000        0.000        0.000         0.000         0.000   \n",
       "2074     0.000        0.000      253.516       194.756         0.998   \n",
       "2075     0.115        0.291      257.809       195.781         0.936   \n",
       "2076     0.030        0.088      221.237       205.407         0.365   \n",
       "2077     0.063        0.172      210.294       204.854         0.577   \n",
       "...        ...          ...          ...           ...           ...   \n",
       "33062    0.051        0.150      206.195       185.499         0.288   \n",
       "33063    0.077        0.255      191.488       185.307         0.301   \n",
       "33064    0.095        0.293      195.961       185.713         0.350   \n",
       "33065    0.168        0.422      204.108       186.470         0.369   \n",
       "33066    0.361        0.670      220.326       186.419         0.454   \n",
       "\n",
       "       NFixations  \n",
       "2073        1.000  \n",
       "2074        2.861  \n",
       "2075        2.146  \n",
       "2076        0.808  \n",
       "2077        1.139  \n",
       "...           ...  \n",
       "33062       0.922  \n",
       "33063       0.953  \n",
       "33064       1.071  \n",
       "33065       0.985  \n",
       "33066       1.019  \n",
       "\n",
       "[36983 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_ia_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backups"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "fold_dict = {}\n",
    "for fold_file in sorted(eyettention_outputs.keys()):\n",
    "    print(f\"Started {fold_file}\")\n",
    "    processed_fold = {}\n",
    "    output_df = eyettention_outputs[fold_file]\n",
    "    grouped_dfs = {key: group for key, group in output_df.groupby(['unique_paragraph_id', 'text_spacing_version'])}\n",
    "    grouped_dfs = {key: split_df_on_zero(group) for key, group in grouped_dfs.items()}\n",
    "    for combo, df_list in tqdm(grouped_dfs.items()):\n",
    "        processed_fix_lists = []\n",
    "        for df in df_list:\n",
    "            df_to_fix_list = []\n",
    "            for i, row in df.iterrows():\n",
    "                df_to_fix_list.append(Fixation(row[\"sp_fix_dur\"], row[\"fix_id\"], row[\"sp_fix_pos\"]))\n",
    "            processed_fix_lists.append(df_to_fix_list)\n",
    "       \n",
    "        paragraph = paragraphs_dict[combo]\n",
    "        adjusted_paragraph = paragraph\n",
    "        for fix_list in processed_fix_lists:\n",
    "            adjusted_paragraph.subj_number += 1\n",
    "            adjusted_paragraph = word_DVs(adjusted_paragraph, fix_list)\n",
    "        \n",
    "        word_means(adjusted_paragraph)\n",
    "        \n",
    "        processed_fold[combo] = adjusted_paragraph\n",
    "        \n",
    "    fold_dict['fold_file'] = processed_fold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onestop_eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
